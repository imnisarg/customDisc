{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Identification for OnInvoice Discount Prediction\n",
    "\n",
    "    1) All the parameters used in prediction of Total Discount can be used in predicting OnInvoice Discount\n",
    "\n",
    "    2) Another very important parameter that we think is important for predicting OnInvoice Discounts is the term period   of   Invoice\n",
    "    \n",
    "To understand this let's understand how invoice Discounts work.\n",
    "\n",
    "Businesses want immediate cash flow on their orders and hence can't wait for their customers to pay them money. So they go to a financing company & sell invoices for which they get a percentage of total Invoice value as initial payment . Financing Company now witholds the responsibility of getting the money from the customer. After customer pays the money to the financing company , the financing company returns the remaining amount after deducting service charges.\n",
    "\n",
    "Typically financing company agrees to give 30 days , 60 days , 90 days ..... time as options for the customer to pay them back . \n",
    "Higher time the customer takes to payback , higher is the service charge deducted by the financing company. So if we customers agree to pay in a short time period , our service charges will be less and hence we can give such customers higher discounts.\n",
    "\n",
    "\n",
    "However we don't have data for the time period of Invoice but we think having that data will help us predict OnInvoice Discounts much more accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from types import FunctionType\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Importing sklearn methods\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Ship-to ID</th>\n",
       "      <th>Volume_2019</th>\n",
       "      <th>Volume_2018</th>\n",
       "      <th>sdfc_Tier</th>\n",
       "      <th>poc_image</th>\n",
       "      <th>segment</th>\n",
       "      <th>sub_segment</th>\n",
       "      <th>Product Set</th>\n",
       "      <th>...</th>\n",
       "      <th>Expected_GTO</th>\n",
       "      <th>Expected_product_volume</th>\n",
       "      <th>loyalty_index</th>\n",
       "      <th>min_order_size_for_discount</th>\n",
       "      <th>inventory_lingering_factor</th>\n",
       "      <th>profit_Product</th>\n",
       "      <th>profitability_indicator</th>\n",
       "      <th>discount_std</th>\n",
       "      <th>upper_limit</th>\n",
       "      <th>Disc_Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29000310</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.557</td>\n",
       "      <td>Tier 0</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>Entertainment Led</td>\n",
       "      <td>Events</td>\n",
       "      <td>RETURNABLE_BOTTLE_JUPILER_JUPILER PILS</td>\n",
       "      <td>...</td>\n",
       "      <td>116.362876</td>\n",
       "      <td>0.395568</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.030049</td>\n",
       "      <td>370.415207</td>\n",
       "      <td>0.474992</td>\n",
       "      <td>840.354946</td>\n",
       "      <td>30.119944</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29000419</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.540</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>RETURNABLE_BOTTLE_PIEDBOEUF_PIEDBOEUF TRIPLE</td>\n",
       "      <td>...</td>\n",
       "      <td>88.943478</td>\n",
       "      <td>0.352174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.057372</td>\n",
       "      <td>207.180476</td>\n",
       "      <td>0.265672</td>\n",
       "      <td>421.813020</td>\n",
       "      <td>21.621963</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29000430</td>\n",
       "      <td>270.97</td>\n",
       "      <td>225.720</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>Drink Led</td>\n",
       "      <td>Party Place</td>\n",
       "      <td>OW_BULK_JUPILER_JUPILER PILS</td>\n",
       "      <td>...</td>\n",
       "      <td>71342.136430</td>\n",
       "      <td>276.519909</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>60.857752</td>\n",
       "      <td>77983.465190</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>188693.263300</td>\n",
       "      <td>39604.153890</td>\n",
       "      <td>0.235763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>29000430</td>\n",
       "      <td>270.97</td>\n",
       "      <td>225.720</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>Drink Led</td>\n",
       "      <td>Party Place</td>\n",
       "      <td>RETURNABLE_BOTTLE_JUPILER_JUPILER PILS</td>\n",
       "      <td>...</td>\n",
       "      <td>6955.593627</td>\n",
       "      <td>23.645077</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.507591</td>\n",
       "      <td>370.415207</td>\n",
       "      <td>0.474992</td>\n",
       "      <td>840.354946</td>\n",
       "      <td>1800.544853</td>\n",
       "      <td>0.267487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>29000430</td>\n",
       "      <td>270.97</td>\n",
       "      <td>225.720</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>Drink Led</td>\n",
       "      <td>Party Place</td>\n",
       "      <td>RETURNABLE_KEG_JUPILER_JUPILER PILS</td>\n",
       "      <td>...</td>\n",
       "      <td>3536.747237</td>\n",
       "      <td>13.908869</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>5.144873</td>\n",
       "      <td>3160.708348</td>\n",
       "      <td>4.053049</td>\n",
       "      <td>11271.537870</td>\n",
       "      <td>948.335453</td>\n",
       "      <td>0.235409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Ship-to ID  Volume_2019  Volume_2018 sdfc_Tier  \\\n",
       "0           0             0    29000310         0.48        0.557    Tier 0   \n",
       "1           1             1    29000419         0.45        0.540    Tier 1   \n",
       "2           2             2    29000430       270.97      225.720    Tier 1   \n",
       "3           3             3    29000430       270.97      225.720    Tier 1   \n",
       "4           4             4    29000430       270.97      225.720    Tier 1   \n",
       "\n",
       "    poc_image            segment     sub_segment  \\\n",
       "0  Mainstream  Entertainment Led          Events   \n",
       "1  Mainstream     Not applicable  Not applicable   \n",
       "2  Mainstream          Drink Led     Party Place   \n",
       "3  Mainstream          Drink Led     Party Place   \n",
       "4  Mainstream          Drink Led     Party Place   \n",
       "\n",
       "                                    Product Set  ...  Expected_GTO  \\\n",
       "0        RETURNABLE_BOTTLE_JUPILER_JUPILER PILS  ...    116.362876   \n",
       "1  RETURNABLE_BOTTLE_PIEDBOEUF_PIEDBOEUF TRIPLE  ...     88.943478   \n",
       "2                  OW_BULK_JUPILER_JUPILER PILS  ...  71342.136430   \n",
       "3        RETURNABLE_BOTTLE_JUPILER_JUPILER PILS  ...   6955.593627   \n",
       "4           RETURNABLE_KEG_JUPILER_JUPILER PILS  ...   3536.747237   \n",
       "\n",
       "  Expected_product_volume loyalty_index min_order_size_for_discount  \\\n",
       "0                0.395568             0                    0.000059   \n",
       "1                0.352174             0                    0.002273   \n",
       "2              276.519909             1                    0.000768   \n",
       "3               23.645077             1                    0.000059   \n",
       "4               13.908869             0                    0.000064   \n",
       "\n",
       "   inventory_lingering_factor  profit_Product  profitability_indicator  \\\n",
       "0                    0.030049      370.415207                 0.474992   \n",
       "1                    0.057372      207.180476                 0.265672   \n",
       "2                   60.857752    77983.465190               100.000000   \n",
       "3                    0.507591      370.415207                 0.474992   \n",
       "4                    5.144873     3160.708348                 4.053049   \n",
       "\n",
       "    discount_std   upper_limit Disc_Percent  \n",
       "0     840.354946     30.119944     0.000000  \n",
       "1     421.813020     21.621963     0.000000  \n",
       "2  188693.263300  39604.153890     0.235763  \n",
       "3     840.354946   1800.544853     0.267487  \n",
       "4   11271.537870    948.335453     0.235409  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data2.xlsx is the data obtained after running the feature engineering code\n",
    "# data3.csv : converted data2.xlsx to data3.csv because of easiness of use of csv files in webapps\n",
    "path = r\"C:\\Users\\NISARG\\Desktop\\mech\\Finance\\Maverick\\CODE\"   #change the path to your local path\n",
    "df = pd.read_csv(path + \"\\data3.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3232645073885446\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "index_test = list()\n",
    "index_train = list()\n",
    "for i in range(len(df['upper_limit'])):\n",
    "    if(df['Discount_Total'][i]>df['upper_limit'][i]):\n",
    "        count+=1\n",
    "        index_test.append(i)\n",
    "    else:\n",
    "        index_train.append(i)\n",
    "print(count/len(df['upper_limit']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.iloc[index_test]\n",
    "df_test = df_test.reset_index()\n",
    "df_train = df.iloc[index_train]\n",
    "df_train = df_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NISARG\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_train.head()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "'''\n",
    "Encoding categorical variables here\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def encode(highGTOData):\n",
    "    lb_make = LabelEncoder()\n",
    "    highGTOData['sdfc_Tier'] = lb_make.fit_transform(highGTOData['sdfc_Tier'])\n",
    "    for i in range(len(highGTOData['GTO_2019'])):\n",
    "        if(highGTOData['poc_image'][i]==0):\n",
    "            highGTOData['poc_image'][i] = \"Mainstream\"\n",
    "    highGTOData['poc_image'] = lb_make.fit_transform(highGTOData['poc_image'])\n",
    "    highGTOData['segment'] = lb_make.fit_transform(highGTOData['segment'])\n",
    "    highGTOData['sub_segment'] = lb_make.fit_transform(highGTOData['sub_segment'])\n",
    "    highGTOData['Product Set'] = lb_make.fit_transform(highGTOData['Product Set'])\n",
    "    highGTOData['Brand'] = lb_make.fit_transform(highGTOData['Brand'])\n",
    "    highGTOData['Sub-Brand'] = lb_make.fit_transform(highGTOData['Sub-Brand'])\n",
    "    highGTOData['Pack_Type'] = lb_make.fit_transform(highGTOData['Pack_Type'])\n",
    "    highGTOData['Returnalility'] = lb_make.fit_transform(highGTOData['Returnalility'])\n",
    "    highGTOData['province'] = lb_make.fit_transform(highGTOData['province'])\n",
    "    highGTOData['GTO_growth'] = highGTOData['Expected_GTO'] - highGTOData['GTO_2019']\n",
    "    return highGTOData\n",
    "\n",
    "\n",
    "df_test = encode(df_test)\n",
    "df_train = encode(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "lowGTOData_train = df_train[df_train.GTO_2019<10000]\n",
    "lowGTOData_test = df_test[df_test.GTO_2019<10000]\n",
    "\n",
    "midGTOData_train = df_train[(df_train.GTO_2019>10000)&(df_train.GTO_2019<50000)]\n",
    "midGTOData_test = df_test[(df_test.GTO_2019>10000)&(df_test.GTO_2019<50000)]\n",
    "\n",
    "highGTOData_train = df_train[df_train.GTO_2019>50000]\n",
    "highGTOData_test = df_test[df_test.GTO_2019>50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Defining the class of machine learning models that we are going to try here\n",
    "'''\n",
    "\n",
    "\n",
    "class Models(object):\n",
    "    \n",
    "    global seed \n",
    "    seed = 34234\n",
    "    \n",
    "    # Initialization \n",
    "    def __init__(self, x_train, x_validation, y_train, y_validation):\n",
    "        # changing input as dataframe to list\n",
    "        self.x_train = [x_train.iloc[i].tolist() for i in range(len(x_train))]\n",
    "        self.x_validation = [x_validation.iloc[i].tolist() for i in range(len(x_validation))]\n",
    "        self.y_train = y_train.tolist()\n",
    "        self.y_validation = y_validation.tolist()\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def print_info(cross_val_scores, mse):\n",
    "        print(\"Cross Validation Scores: \", cross_val_scores)\n",
    "        print(\"Mean Squared Error: \", mse)\n",
    "        \n",
    "        \n",
    "    # Linear Regression \n",
    "    def linear_regression(self, x_train, x_validation,  y_train, y_validation):\n",
    "        reg = linear_model.LinearRegression()\n",
    "        # X = np.array(X).reshape([-1, 1])\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        y_pred_list = reg.predict(self.x_validation)\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, y_pred_list))\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(reg, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,reg.predict(self.x_train)))\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        print(\"\\nLinear Regression Model\")\n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse\n",
    "        \n",
    "    # Random Forest Regression model \n",
    "    def random_forest(self, x_train, x_validation,  y_train, y_validation):\n",
    "        rfr = RandomForestRegressor(n_estimators=8, max_depth=8, random_state=12, verbose=0)\n",
    "        # X = np.array(X).reshape([-1, 1])\n",
    "        rfr.fit(self.x_train, self.y_train)\n",
    "        y_pred_list = rfr.predict(self.x_validation)\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, y_pred_list))\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(rfr, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,rfr.predict(self.x_train)))\n",
    "        print(\"\\nRandom Forest Regressor\")\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse\n",
    "            \n",
    "    # Lasso method \n",
    "    def lasso(self, x_train, x_validation,  y_train, y_validation):\n",
    "        reg = linear_model.Lasso(alpha = 0.1)\n",
    "        # X = np.array(X).reshape([-1, 1])\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        y_pred_list = reg.predict(self.x_validation)\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, y_pred_list))\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(reg, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,reg.predict(self.x_train)))\n",
    "        print(\"\\nLasso Regression Model\")\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse\n",
    "    \n",
    "    # Ridge method \n",
    "    def ridge(self, x_train, x_validation,  y_train, y_validation):\n",
    "        reg = linear_model.Ridge(alpha = 0.1)\n",
    "        # X = np.array(X).reshape([-1, 1])\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        y_pred_list = reg.predict(self.x_validation)\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, y_pred_list))\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(reg, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,reg.predict(self.x_train)))\n",
    "        print(\"\\nRidge Regression Model\")\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse\n",
    "    \n",
    "    \n",
    "     # CART method \n",
    "    def CART(self, x_train, x_validation,  y_train, y_validation):\n",
    "        reg =  tree.DecisionTreeRegressor()\n",
    "        # X = np.array(X).reshape([-1, 1])\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        y_pred_list = reg.predict(self.x_validation)\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, y_pred_list))\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(reg, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,reg.predict(self.x_train)))\n",
    "        print(\"\\nCART Regression Model\")\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse\n",
    "    \n",
    "    # Gradient Boosing Regressor\n",
    "    def GBR(self, x_train, x_validation,  y_train, y_validation):\n",
    "        gbr = GradientBoostingRegressor(n_estimators=175, learning_rate=0.08, max_depth=3, random_state=1232, loss='ls')\n",
    "        gbr.fit(self.x_train, self.y_train)\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(gbr, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,gbr.predict(self.x_train)))\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, gbr.predict(self.x_validation)))\n",
    "        print(\"mse = \",mse)\n",
    "        print('\\nGradient Boosting Regressor')\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        \n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowGTOData_train = lowGTOData_train.reset_index()\n",
    "lowGTOData_test = lowGTOData_test.reset_index()\n",
    "target_train = lowGTOData_train['OnInvoice Discount(LCU)']\n",
    "target_test = lowGTOData_test['OnInvoice Discount(LCU)']\n",
    "colsToKeep = ['Volume_2019' , 'Volume_2018'  , 'Expected_GTO'  , 'Expected_product_volume', 'profitability_indicator' , 'upper_limit'  ,'sdfc_Tier'  , 'loyalty_index' , 'Returnalility', 'market_cap' ]\n",
    "features_train = lowGTOData_train[colsToKeep]\n",
    "features_test = lowGTOData_test[colsToKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ERROR =  209.17050216238943\n",
      "\n",
      "Linear Regression Model\n",
      "Cross Validation Scores:  [ 2.75836720e-01  1.97793669e-02  8.83971554e-02  2.56159582e-01\n",
      "  2.74671339e-01 -1.52580988e+10  2.67604878e-01 -1.38925911e+01\n",
      "  2.43688677e-01  2.56289702e-01]\n",
      "Mean Squared Error:  375.71502450074723\n",
      "MEAN CROSS VAL SCORES= -1525809883.9408245\n",
      "\n",
      "Random Forest Regressor\n",
      "TRAINING ERROR =  137.3550907424985\n",
      "Cross Validation Scores:  [0.52995426 0.56266093 0.56374022 0.47013767 0.50670935 0.46617072\n",
      " 0.55730387 0.54710638 0.55976663 0.53439179]\n",
      "Mean Squared Error:  349.9925860547361\n",
      "MEAN CROSS VAL SCORES= 0.5297941807492081\n",
      "\n",
      "Lasso Regression Model\n",
      "TRAINING ERROR =  209.20852123400243\n",
      "Cross Validation Scores:  [ 2.75757192e-01  1.89057285e-02  8.92729989e-02  2.56919834e-01\n",
      "  2.75304480e-01 -1.53942126e+10  2.66349803e-01 -1.38888770e+01\n",
      "  2.44542818e-01  2.56388663e-01]\n",
      "Mean Squared Error:  375.7369180579738\n",
      "MEAN CROSS VAL SCORES= -1539421261.0304525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.56443e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.47388e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.4355e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.36404e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.34224e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.43083e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.45439e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.45855e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.39535e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.41701e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Regression Model\n",
      "TRAINING ERROR =  209.17050411953647\n",
      "Cross Validation Scores:  [ 2.75837755e-01  1.97715083e-02  8.84059875e-02  2.56170248e-01\n",
      "  2.74678590e-01 -1.52591021e+10  2.67597753e-01 -1.38925969e+01\n",
      "  2.43698312e-01  2.56292851e-01]\n",
      "Mean Squared Error:  375.71475266653783\n",
      "MEAN CROSS VAL SCORES= -1525910211.5622506\n",
      "\n",
      "CART Regression Model\n",
      "TRAINING ERROR =  7.365139052817077e-16\n",
      "Cross Validation Scores:  [ 0.02410195  0.28601802  0.13867957  0.12418402  0.07608494 -0.08561846\n",
      "  0.08596407  0.26440041  0.0740126   0.1164679 ]\n",
      "Mean Squared Error:  387.59867136369564\n",
      "MEAN CROSS VAL SCORES= 0.11042950194673126\n",
      "mse =  340.7099992320587\n",
      "\n",
      "Gradient Boosting Regressor\n",
      "TRAINING ERROR =  131.00147197111852\n",
      "Cross Validation Scores:  [0.52847839 0.53471941 0.57589338 0.49151801 0.56957272 0.51063966\n",
      " 0.56089954 0.51839653 0.59377564 0.55715815]\n",
      "Mean Squared Error:  340.7099992320587\n",
      "MEAN CROSS VAL SCORES= 0.5441051422106856\n"
     ]
    }
   ],
   "source": [
    "methods = [x for x, y in Models.__dict__.items() if type(y) == FunctionType]\n",
    "methods.remove('__init__')\n",
    "for model in methods:\n",
    "    reg = Models(features_train, features_test, target_train, target_test)\n",
    "    cross_val_scores, mse = getattr(reg, model)(features_train, features_test, target_train, target_test)\n",
    "    print(\"MEAN CROSS VAL SCORES=\" , np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments for lowGTOData :\n",
    "1) Since our training data is correct data (data where discounts are correctly given ) , we would like our Machine Learning model to give minimum training error.\n",
    "\n",
    "2) For selecting the best model , we use the criteria : Less Training Error , high R^2 values\n",
    "\n",
    "3) CART Model gives least training error but we can see that cross validation scores are not good , this means that the model is overfitting\n",
    "\n",
    "4) Gradient Boosting Regressor performs the best in both Training Error and Cross Validation Scores Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Keeping the features as seen from EXPLORATORY DATA ANALYSIS\n",
    "'''\n",
    "\n",
    "midGTOData_train = midGTOData_train.reset_index()\n",
    "midGTOData_test = midGTOData_test.reset_index()\n",
    "target_train = midGTOData_train['Discount_Total']\n",
    "target_test = midGTOData_test['Discount_Total']\n",
    "colsToKeep = ['Volume_2019' , 'Volume_2018' ,'Volume_2019 Product' ,'Expected_GTO','Expected_product_volume' , 'profitability_indicator' , 'upper_limit'  ,'sdfc_Tier'  , 'loyalty_index' , 'Returnalility',  'inventory_lingering_factor', 'market_cap',\n",
    "       'order_size']\n",
    "features_train = midGTOData_train[colsToKeep]\n",
    "features_test = midGTOData_test[colsToKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ERROR =  2157.655855188812\n",
      "\n",
      "Linear Regression Model\n",
      "Cross Validation Scores:  [0.63800041 0.23246567 0.38247191 0.31567495 0.41035225 0.52893829\n",
      " 0.47113808 0.39799634 0.50792226 0.47252448]\n",
      "Mean Squared Error:  6583.829538001789\n",
      "MEAN CROSS VAL SCORES= 0.43574846519336735\n",
      "\n",
      "Random Forest Regressor\n",
      "TRAINING ERROR =  1424.0698486921524\n",
      "Cross Validation Scores:  [0.57852706 0.31551433 0.47641717 0.35457732 0.33568022 0.65900386\n",
      " 0.62967686 0.38368241 0.52126377 0.49137169]\n",
      "Mean Squared Error:  6414.869674902147\n",
      "MEAN CROSS VAL SCORES= 0.4745714696634106\n",
      "\n",
      "Lasso Regression Model\n",
      "TRAINING ERROR =  2157.662605321827\n",
      "Cross Validation Scores:  [0.63803764 0.23291445 0.38248092 0.31609428 0.41054297 0.52883927\n",
      " 0.47129861 0.398313   0.50578807 0.47294024]\n",
      "Mean Squared Error:  6583.274571440101\n",
      "MEAN CROSS VAL SCORES= 0.4357249459524747\n",
      "\n",
      "Ridge Regression Model\n",
      "TRAINING ERROR =  2158.0184294360824\n",
      "Cross Validation Scores:  [0.63808368 0.23631229 0.38197558 0.31789365 0.4114996  0.52757936\n",
      " 0.47113904 0.39978756 0.5003957  0.47526495]\n",
      "Mean Squared Error:  6581.304634455495\n",
      "MEAN CROSS VAL SCORES= 0.43599314105084713\n",
      "\n",
      "CART Regression Model\n",
      "TRAINING ERROR =  0.0\n",
      "Cross Validation Scores:  [ 0.46841736 -0.44663945 -0.07478901  0.07986662 -0.16864773  0.34276366\n",
      "  0.48028362 -0.03005015  0.11219152 -0.0520965 ]\n",
      "Mean Squared Error:  6554.874172562412\n",
      "MEAN CROSS VAL SCORES= 0.07112999491811797\n",
      "mse =  6359.643294209725\n",
      "\n",
      "Gradient Boosting Regressor\n",
      "TRAINING ERROR =  1411.5017787380566\n",
      "Cross Validation Scores:  [0.56251289 0.29534455 0.51148785 0.31107987 0.42174193 0.68639207\n",
      " 0.60258065 0.41217177 0.57332874 0.52340454]\n",
      "Mean Squared Error:  6359.643294209725\n",
      "MEAN CROSS VAL SCORES= 0.4900044850931503\n"
     ]
    }
   ],
   "source": [
    "methods = [x for x, y in Models.__dict__.items() if type(y) == FunctionType]\n",
    "methods.remove('__init__')\n",
    "for model in methods:\n",
    "    reg = Models(features_train, features_test, target_train, target_test)\n",
    "    cross_val_scores, mse = getattr(reg, model)(features_train, features_test, target_train, target_test)\n",
    "    print(\"MEAN CROSS VAL SCORES=\" , np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments for mid GTO Data\n",
    "1) CART REGRESSION MODEL OVERFITS , EVEN THOUGH WE HAVE zero Training error but cross validation scores are very less\n",
    "\n",
    "2) Gradient boosting Regressor has less training error and the highest k fold cross validation score\n",
    "\n",
    "3) GBR model fits best for mid GTO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Keeping the features as seen from EXPLORATORY DATA ANALYSIS\n",
    "'''\n",
    "\n",
    "\n",
    "highGTOData_train = highGTOData_train.reset_index()\n",
    "highGTOData_test = highGTOData_test.reset_index()\n",
    "target_train = highGTOData_train['Discount_Total']\n",
    "target_test = highGTOData_test['Discount_Total']\n",
    "colsToKeep = ['Volume_2019' , 'Volume_2018' ,'Volume_2019 Product' ,'Expected_GTO','Expected_product_volume' , 'profitability_indicator' , 'upper_limit'  ,  'inventory_lingering_factor',\n",
    "       'order_size']\n",
    "features_train = highGTOData_train[colsToKeep]\n",
    "features_test = highGTOData_test[colsToKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ERROR =  11592.764707271046\n",
      "\n",
      "Linear Regression Model\n",
      "Cross Validation Scores:  [-1.06087019 -0.36632146  0.97420802  0.72035285  0.62682464 -0.06819141\n",
      "  0.49322678 -2.2610839   0.87362034  0.91377639]\n",
      "Mean Squared Error:  124995.12651733206\n",
      "MEAN CROSS VAL SCORES= 0.0845542055601822\n",
      "\n",
      "Random Forest Regressor\n",
      "TRAINING ERROR =  5966.083708326815\n",
      "Cross Validation Scores:  [-1.74860924  0.5434003   0.91425773  0.85503962  0.62815798 -0.09866692\n",
      "  0.46652807 -4.63388039  0.8523974   0.92125103]\n",
      "Mean Squared Error:  171986.4990619022\n",
      "MEAN CROSS VAL SCORES= -0.1300124437627878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8735745248.855309, tolerance: 17511858.16904576\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5648836278.466648, tolerance: 16989957.83912539\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6541686295.815524, tolerance: 17093948.063802466\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8427322473.458778, tolerance: 11503909.394607509\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7625020321.91488, tolerance: 16550956.939804306\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8032029901.700499, tolerance: 17078545.52190337\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8368239727.70475, tolerance: 17258069.28391088\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8239073469.532127, tolerance: 17242090.63033597\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8441414126.525116, tolerance: 17227179.79658202\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6920556723.114244, tolerance: 11651871.867754962\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7875674610.5744705, tolerance: 14860317.325613242\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Model\n",
      "TRAINING ERROR =  11592.8733428284\n",
      "Cross Validation Scores:  [-1.07080799 -0.36169851  0.97953099  0.72041248  0.62548444 -0.07059253\n",
      "  0.48980501 -2.07415161  0.87716266  0.91381811]\n",
      "Mean Squared Error:  124878.77966440414\n",
      "MEAN CROSS VAL SCORES= 0.1028963054053718\n",
      "\n",
      "Ridge Regression Model\n",
      "TRAINING ERROR =  11592.81823974513\n",
      "Cross Validation Scores:  [-1.05852978 -0.36697204  0.97403141  0.72024496  0.62874838 -0.06852993\n",
      "  0.49177446 -2.12594403  0.87364746  0.91384709]\n",
      "Mean Squared Error:  125016.88051406432\n",
      "MEAN CROSS VAL SCORES= 0.09823179709549928\n",
      "\n",
      "CART Regression Model\n",
      "TRAINING ERROR =  0.0\n",
      "Cross Validation Scores:  [ -1.59291365   0.3146687    0.95990044   0.74736021   0.49807266\n",
      "  -0.89021095   0.15780425 -29.12889898   0.83467154   0.89431004]\n",
      "Mean Squared Error:  169473.75763667212\n",
      "MEAN CROSS VAL SCORES= -2.7205235737808118\n",
      "mse =  174374.6010934097\n",
      "\n",
      "Gradient Boosting Regressor\n",
      "TRAINING ERROR =  1573.8869325240246\n",
      "Cross Validation Scores:  [-1.86965283  0.5372397   0.9313883   0.50634274  0.57041546 -0.65942433\n",
      "  0.35410652 -1.99967836  0.82529292  0.94767677]\n",
      "Mean Squared Error:  174374.6010934097\n",
      "MEAN CROSS VAL SCORES= 0.014370688817669963\n"
     ]
    }
   ],
   "source": [
    "methods = [x for x, y in Models.__dict__.items() if type(y) == FunctionType]\n",
    "methods.remove('__init__')\n",
    "for model in methods:\n",
    "    reg = Models(features_train, features_test, target_train, target_test)\n",
    "    cross_val_scores, mse = getattr(reg, model)(features_train, features_test, target_train, target_test)\n",
    "    print(\"MEAN CROSS VAL SCORES=\" , np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments for High GTO Data\n",
    "1) Linear Models are seen to have better cross validation scores as compared to GBR even though they have higher training error\n",
    "\n",
    "2) Combining results of GBR & Lasso could be an ideal choice for High GTO Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if OnInvoice Discount Predicted is less than predicted Total Discount  (given Total Discount is +ve) ?\n",
    "\n",
    "Ans : Since we know that Total Discount can be spreaded into 2 components & hence split the remaining into Off Invoice Discount\n",
    "\n",
    "# What if OnInvoice Discount Predicted is more than predicted Total Discount (given Total Discount is +ve) ?\n",
    " \n",
    "Ans : We would have to adjust the OnInvoice Discount offered --- Make OnInvoice Discount = Predicted Total Discount & OffInvoice Discount = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
