{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Identification to Predict the Total Discount\n",
    "\n",
    "We would be training different Machine Learning models to Predict Total Discount that needs to be given to a POC.\n",
    "\n",
    "Then we would split the total Discount obtained into 2 parts : On Invoice Discount & Off Invoice Discount\n",
    "\n",
    "In this notebook , we try to obtain the best model for Total Discount Prediction . We introduce our train test split strategy and also how we are dividing the data based on GTO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from types import FunctionType\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Importing sklearn methods\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Ship-to ID</th>\n",
       "      <th>Volume_2019</th>\n",
       "      <th>Volume_2018</th>\n",
       "      <th>sdfc_Tier</th>\n",
       "      <th>poc_image</th>\n",
       "      <th>segment</th>\n",
       "      <th>sub_segment</th>\n",
       "      <th>Product Set</th>\n",
       "      <th>...</th>\n",
       "      <th>Expected_GTO</th>\n",
       "      <th>Expected_product_volume</th>\n",
       "      <th>loyalty_index</th>\n",
       "      <th>min_order_size_for_discount</th>\n",
       "      <th>inventory_lingering_factor</th>\n",
       "      <th>profit_Product</th>\n",
       "      <th>profitability_indicator</th>\n",
       "      <th>discount_std</th>\n",
       "      <th>upper_limit</th>\n",
       "      <th>Disc_Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29000310</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.557</td>\n",
       "      <td>Tier 0</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>Entertainment Led</td>\n",
       "      <td>Events</td>\n",
       "      <td>RETURNABLE_BOTTLE_JUPILER_JUPILER PILS</td>\n",
       "      <td>...</td>\n",
       "      <td>116.362876</td>\n",
       "      <td>0.395568</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.030049</td>\n",
       "      <td>370.415207</td>\n",
       "      <td>0.474992</td>\n",
       "      <td>840.354946</td>\n",
       "      <td>30.119944</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29000419</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.540</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>RETURNABLE_BOTTLE_PIEDBOEUF_PIEDBOEUF TRIPLE</td>\n",
       "      <td>...</td>\n",
       "      <td>88.943478</td>\n",
       "      <td>0.352174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.057372</td>\n",
       "      <td>207.180476</td>\n",
       "      <td>0.265672</td>\n",
       "      <td>421.813020</td>\n",
       "      <td>21.621963</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29000430</td>\n",
       "      <td>270.97</td>\n",
       "      <td>225.720</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>Drink Led</td>\n",
       "      <td>Party Place</td>\n",
       "      <td>OW_BULK_JUPILER_JUPILER PILS</td>\n",
       "      <td>...</td>\n",
       "      <td>71342.136430</td>\n",
       "      <td>276.519909</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>60.857752</td>\n",
       "      <td>77983.465190</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>188693.263300</td>\n",
       "      <td>39604.153890</td>\n",
       "      <td>0.235763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>29000430</td>\n",
       "      <td>270.97</td>\n",
       "      <td>225.720</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>Drink Led</td>\n",
       "      <td>Party Place</td>\n",
       "      <td>RETURNABLE_BOTTLE_JUPILER_JUPILER PILS</td>\n",
       "      <td>...</td>\n",
       "      <td>6955.593627</td>\n",
       "      <td>23.645077</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.507591</td>\n",
       "      <td>370.415207</td>\n",
       "      <td>0.474992</td>\n",
       "      <td>840.354946</td>\n",
       "      <td>1800.544853</td>\n",
       "      <td>0.267487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>29000430</td>\n",
       "      <td>270.97</td>\n",
       "      <td>225.720</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>Drink Led</td>\n",
       "      <td>Party Place</td>\n",
       "      <td>RETURNABLE_KEG_JUPILER_JUPILER PILS</td>\n",
       "      <td>...</td>\n",
       "      <td>3536.747237</td>\n",
       "      <td>13.908869</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>5.144873</td>\n",
       "      <td>3160.708348</td>\n",
       "      <td>4.053049</td>\n",
       "      <td>11271.537870</td>\n",
       "      <td>948.335453</td>\n",
       "      <td>0.235409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Ship-to ID  Volume_2019  Volume_2018 sdfc_Tier  \\\n",
       "0           0             0    29000310         0.48        0.557    Tier 0   \n",
       "1           1             1    29000419         0.45        0.540    Tier 1   \n",
       "2           2             2    29000430       270.97      225.720    Tier 1   \n",
       "3           3             3    29000430       270.97      225.720    Tier 1   \n",
       "4           4             4    29000430       270.97      225.720    Tier 1   \n",
       "\n",
       "    poc_image            segment     sub_segment  \\\n",
       "0  Mainstream  Entertainment Led          Events   \n",
       "1  Mainstream     Not applicable  Not applicable   \n",
       "2  Mainstream          Drink Led     Party Place   \n",
       "3  Mainstream          Drink Led     Party Place   \n",
       "4  Mainstream          Drink Led     Party Place   \n",
       "\n",
       "                                    Product Set  ...  Expected_GTO  \\\n",
       "0        RETURNABLE_BOTTLE_JUPILER_JUPILER PILS  ...    116.362876   \n",
       "1  RETURNABLE_BOTTLE_PIEDBOEUF_PIEDBOEUF TRIPLE  ...     88.943478   \n",
       "2                  OW_BULK_JUPILER_JUPILER PILS  ...  71342.136430   \n",
       "3        RETURNABLE_BOTTLE_JUPILER_JUPILER PILS  ...   6955.593627   \n",
       "4           RETURNABLE_KEG_JUPILER_JUPILER PILS  ...   3536.747237   \n",
       "\n",
       "  Expected_product_volume loyalty_index min_order_size_for_discount  \\\n",
       "0                0.395568             0                    0.000059   \n",
       "1                0.352174             0                    0.002273   \n",
       "2              276.519909             1                    0.000768   \n",
       "3               23.645077             1                    0.000059   \n",
       "4               13.908869             0                    0.000064   \n",
       "\n",
       "   inventory_lingering_factor  profit_Product  profitability_indicator  \\\n",
       "0                    0.030049      370.415207                 0.474992   \n",
       "1                    0.057372      207.180476                 0.265672   \n",
       "2                   60.857752    77983.465190               100.000000   \n",
       "3                    0.507591      370.415207                 0.474992   \n",
       "4                    5.144873     3160.708348                 4.053049   \n",
       "\n",
       "    discount_std   upper_limit Disc_Percent  \n",
       "0     840.354946     30.119944     0.000000  \n",
       "1     421.813020     21.621963     0.000000  \n",
       "2  188693.263300  39604.153890     0.235763  \n",
       "3     840.354946   1800.544853     0.267487  \n",
       "4   11271.537870    948.335453     0.235409  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data2.xlsx is the data obtained after running the feature engineering code\n",
    "# data3.csv : converted data2.xlsx to data3.csv because of easiness of use of csv files in webapps\n",
    "path = r\"C:\\Users\\NISARG\\Desktop\\mech\\Finance\\Maverick\\CODE\"   #change the path to your local path\n",
    "df = pd.read_csv(path + \"\\data3.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST DATA CREATION STRATEGY\n",
    "\n",
    "Aim of the split is to identify data that is being **discounted correctly** and use that data as **train data**. Training model based on this data will help us create a model that has seen only **correctly discounted data** and hence when used in testing , it will give us the correct discounts for the data that is not being discounted correctly\n",
    "\n",
    "# Strategy\n",
    "\n",
    "We use **upper_limit column** to do the requisite train test split.\n",
    "\n",
    "As explained in Exploratory Data Analysis Notebook , there are 2 terms in upper limit : one which takes care of the **profitability of a particular product set** for ABInBev and the other which takes care of the **growth potential of POC**.\n",
    "\n",
    "Upper Limit is then **scaled** by a factor of **1.2** \n",
    "\n",
    "If for a particular POC , discount given is **lesser than upper limit** as defined above , we can be assured that discount given to that **POC is correct** and we can **include it in our train dataset**\n",
    "However if the total discount is **greater than upper limit**, then it is **wrongly discounted** and we include that in test dataset ( the dataset for which we want to correct the discount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3232645073885446\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = 0\n",
    "index_test = list()\n",
    "index_train = list()\n",
    "for i in range(len(df['upper_limit'])):\n",
    "    if(df['Discount_Total'][i]>df['upper_limit'][i]):\n",
    "        count+=1\n",
    "        index_test.append(i)\n",
    "    else:\n",
    "        index_train.append(i)\n",
    "print(count/len(df['upper_limit']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Here we get the train and test datasets based on the logic described above\n",
    "'''\n",
    "\n",
    "df_test = df.iloc[index_test]\n",
    "df_test = df_test.reset_index()\n",
    "df_train = df.iloc[index_train]\n",
    "df_train = df_train.reset_index()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Encoding categorical variables here\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def encode(highGTOData):\n",
    "    lb_make = LabelEncoder()\n",
    "    highGTOData['sdfc_Tier'] = lb_make.fit_transform(highGTOData['sdfc_Tier'])\n",
    "    for i in range(len(highGTOData['GTO_2019'])):\n",
    "        if(highGTOData['poc_image'][i]==0):\n",
    "            highGTOData['poc_image'][i] = \"Mainstream\"\n",
    "    highGTOData['poc_image'] = lb_make.fit_transform(highGTOData['poc_image'])\n",
    "    highGTOData['segment'] = lb_make.fit_transform(highGTOData['segment'])\n",
    "    highGTOData['sub_segment'] = lb_make.fit_transform(highGTOData['sub_segment'])\n",
    "    highGTOData['Product Set'] = lb_make.fit_transform(highGTOData['Product Set'])\n",
    "    highGTOData['Brand'] = lb_make.fit_transform(highGTOData['Brand'])\n",
    "    highGTOData['Sub-Brand'] = lb_make.fit_transform(highGTOData['Sub-Brand'])\n",
    "    highGTOData['Pack_Type'] = lb_make.fit_transform(highGTOData['Pack_Type'])\n",
    "    highGTOData['Returnalility'] = lb_make.fit_transform(highGTOData['Returnalility'])\n",
    "    highGTOData['province'] = lb_make.fit_transform(highGTOData['province'])\n",
    "    highGTOData['GTO_growth'] = highGTOData['Expected_GTO'] - highGTOData['GTO_2019']\n",
    "    return highGTOData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NISARG\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "df_test = encode(df_test)\n",
    "df_train = encode(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Division \n",
    "\n",
    "We divide the dataset into 3 parts based on **GTO_2019** . Since statistically dominant features for these 3 parts vary , creating different machine learning models for them gives better results.\n",
    "\n",
    "Dataset is divided into the following 3 parts\n",
    "\n",
    "    1) LOW GTO : GTO < 10000\n",
    "    \n",
    "    2) Mid GTO : GTO > 10000 & GTO < 50000\n",
    "    \n",
    "    3) HIGH GTO : GTO > 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "lowGTOData_train = df_train[df_train.GTO_2019<10000]\n",
    "lowGTOData_test = df_test[df_test.GTO_2019<10000]\n",
    "\n",
    "midGTOData_train = df_train[(df_train.GTO_2019>10000)&(df_train.GTO_2019<50000)]\n",
    "midGTOData_test = df_test[(df_test.GTO_2019>10000)&(df_test.GTO_2019<50000)]\n",
    "\n",
    "highGTOData_train = df_train[df_train.GTO_2019>50000]\n",
    "highGTOData_test = df_test[df_test.GTO_2019>50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Defining the class of machine learning models that we are going to try here\n",
    "'''\n",
    "\n",
    "\n",
    "class Models(object):\n",
    "    \n",
    "    global seed \n",
    "    seed = 34234\n",
    "    \n",
    "    # Initialization \n",
    "    def __init__(self, x_train, x_validation, y_train, y_validation):\n",
    "        # changing input as dataframe to list\n",
    "        self.x_train = [x_train.iloc[i].tolist() for i in range(len(x_train))]\n",
    "        self.x_validation = [x_validation.iloc[i].tolist() for i in range(len(x_validation))]\n",
    "        self.y_train = y_train.tolist()\n",
    "        self.y_validation = y_validation.tolist()\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def print_info(cross_val_scores, mse):\n",
    "        print(\"Cross Validation Scores: \", cross_val_scores)\n",
    "        print(\"Mean Squared Error: \", mse)\n",
    "        \n",
    "        \n",
    "    # Linear Regression \n",
    "    def linear_regression(self, x_train, x_validation,  y_train, y_validation):\n",
    "        reg = linear_model.LinearRegression()\n",
    "        # X = np.array(X).reshape([-1, 1])\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        y_pred_list = reg.predict(self.x_validation)\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, y_pred_list))\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(reg, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,reg.predict(self.x_train)))\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        print(\"\\nLinear Regression Model\")\n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse\n",
    "        \n",
    "    # Random Forest Regression model \n",
    "    def random_forest(self, x_train, x_validation,  y_train, y_validation):\n",
    "        rfr = RandomForestRegressor(n_estimators=8, max_depth=8, random_state=12, verbose=0)\n",
    "        # X = np.array(X).reshape([-1, 1])\n",
    "        rfr.fit(self.x_train, self.y_train)\n",
    "        y_pred_list = rfr.predict(self.x_validation)\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, y_pred_list))\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(rfr, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,rfr.predict(self.x_train)))\n",
    "        print(\"\\nRandom Forest Regressor\")\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse\n",
    "            \n",
    "    # Lasso method \n",
    "    def lasso(self, x_train, x_validation,  y_train, y_validation):\n",
    "        reg = linear_model.Lasso(alpha = 0.1)\n",
    "        # X = np.array(X).reshape([-1, 1])\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        y_pred_list = reg.predict(self.x_validation)\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, y_pred_list))\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(reg, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,reg.predict(self.x_train)))\n",
    "        print(\"\\nLasso Regression Model\")\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse\n",
    "    \n",
    "    # Ridge method \n",
    "    def ridge(self, x_train, x_validation,  y_train, y_validation):\n",
    "        reg = linear_model.Ridge(alpha = 0.1)\n",
    "        # X = np.array(X).reshape([-1, 1])\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        y_pred_list = reg.predict(self.x_validation)\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, y_pred_list))\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(reg, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,reg.predict(self.x_train)))\n",
    "        print(\"\\nRidge Regression Model\")\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse\n",
    "    \n",
    "    \n",
    "     # CART method \n",
    "    def CART(self, x_train, x_validation,  y_train, y_validation):\n",
    "        reg =  tree.DecisionTreeRegressor()\n",
    "        # X = np.array(X).reshape([-1, 1])\n",
    "        reg.fit(self.x_train, self.y_train)\n",
    "        y_pred_list = reg.predict(self.x_validation)\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, y_pred_list))\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(reg, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,reg.predict(self.x_train)))\n",
    "        print(\"\\nCART Regression Model\")\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse\n",
    "    \n",
    "    # Gradient Boosing Regressor\n",
    "    def GBR(self, x_train, x_validation,  y_train, y_validation):\n",
    "        gbr = GradientBoostingRegressor(n_estimators=175, learning_rate=0.08, max_depth=3, random_state=1232, loss='ls')\n",
    "        gbr.fit(self.x_train, self.y_train)\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cross_val_scores = cross_val_score(gbr, self.x_train, self.y_train, cv=kfold )\n",
    "        mse_train = math.sqrt(mean_squared_error(self.y_train,gbr.predict(self.x_train)))\n",
    "        mse = math.sqrt(mean_squared_error(self.y_validation, gbr.predict(self.x_validation)))\n",
    "        print(\"mse = \",mse)\n",
    "        print('\\nGradient Boosting Regressor')\n",
    "        print(\"TRAINING ERROR = \" , mse_train)\n",
    "        \n",
    "        self.print_info(cross_val_scores, mse)\n",
    "        return cross_val_scores, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Keeping the essential columns as seen from the Exploratory Data Analysis\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "lowGTOData_train = lowGTOData_train.reset_index()\n",
    "lowGTOData_test = lowGTOData_test.reset_index()\n",
    "target_train = lowGTOData_train['Discount_Total']\n",
    "target_test = lowGTOData_test['Discount_Total']\n",
    "colsToKeep = ['Volume_2019' , 'Volume_2018'  , 'Expected_GTO'  , 'Expected_product_volume', 'profitability_indicator' , 'upper_limit'  ,'sdfc_Tier'  , 'loyalty_index' , 'Returnalility', 'market_cap' ]\n",
    "features_train = lowGTOData_train[colsToKeep]\n",
    "features_test = lowGTOData_test[colsToKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ERROR =  347.87168854519183\n",
      "\n",
      "Linear Regression Model\n",
      "Cross Validation Scores:  [ 4.00787233e-01  1.65688762e-01  6.04759808e-02  3.29433468e-01\n",
      "  3.62163103e-01 -6.76259540e+10  2.75470063e-01 -1.91311127e+01\n",
      "  3.09435497e-01  3.11794915e-01]\n",
      "Mean Squared Error:  663.6101020307376\n",
      "MEAN CROSS VAL SCORES= -6762595399.491838\n",
      "\n",
      "Random Forest Regressor\n",
      "TRAINING ERROR =  140.9393411095392\n",
      "Cross Validation Scores:  [0.69403482 0.65730069 0.88129082 0.62996554 0.77444463 0.87657898\n",
      " 0.91937588 0.73961251 0.71284645 0.70896735]\n",
      "Mean Squared Error:  1107.173425684565\n",
      "MEAN CROSS VAL SCORES= 0.7594417679010417\n",
      "\n",
      "Lasso Regression Model\n",
      "TRAINING ERROR =  347.8945502208254\n",
      "Cross Validation Scores:  [ 4.00027013e-01  1.65209415e-01  6.10981997e-02  3.30323315e-01\n",
      "  3.61302651e-01 -6.76247602e+10  2.76700198e-01 -1.91234010e+01\n",
      "  3.09118247e-01  3.11419600e-01]\n",
      "Mean Squared Error:  663.7064727308415\n",
      "MEAN CROSS VAL SCORES= -6762476018.822924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.56443e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.47388e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.4355e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.36404e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.34224e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.43083e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.45439e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.45855e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.39535e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.41701e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Regression Model\n",
      "TRAINING ERROR =  347.8716895234163\n",
      "Cross Validation Scores:  [ 4.00782354e-01  1.65684153e-01  6.04825907e-02  3.29442825e-01\n",
      "  3.62157623e-01 -6.76259100e+10  2.75490312e-01 -1.91310482e+01\n",
      "  3.09433493e-01  3.11793406e-01]\n",
      "Mean Squared Error:  663.6104011115797\n",
      "MEAN CROSS VAL SCORES= -6762591003.736961\n",
      "\n",
      "CART Regression Model\n",
      "TRAINING ERROR =  2.1725896842663301e-16\n",
      "Cross Validation Scores:  [0.46958692 0.49853673 0.79217374 0.33782931 0.50591797 0.76828446\n",
      " 0.85416908 0.5326938  0.57554501 0.60132816]\n",
      "Mean Squared Error:  1041.1524816616027\n",
      "MEAN CROSS VAL SCORES= 0.5936065169212928\n",
      "mse =  1158.7989157671286\n",
      "\n",
      "Gradient Boosting Regressor\n",
      "TRAINING ERROR =  139.34335533706295\n",
      "Cross Validation Scores:  [0.69580969 0.65833065 0.88725394 0.67072566 0.7858876  0.89254566\n",
      " 0.93262279 0.7447072  0.73465726 0.69742913]\n",
      "Mean Squared Error:  1158.7989157671286\n",
      "MEAN CROSS VAL SCORES= 0.7699969581837152\n"
     ]
    }
   ],
   "source": [
    "methods = [x for x, y in Models.__dict__.items() if type(y) == FunctionType]\n",
    "methods.remove('__init__')\n",
    "for model in methods:\n",
    "    reg = Models(features_train, features_test, target_train, target_test)\n",
    "    cross_val_scores, mse = getattr(reg, model)(features_train, features_test, target_train, target_test)\n",
    "    print(\"MEAN CROSS VAL SCORES=\" , np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments for lowGTOData :\n",
    "1) Since our training data is correct data (data where discounts are correctly given ) , we would like our Machine Learning model\n",
    "to give minimum training error.\n",
    "\n",
    "2) For selecting the best model , we use the criteria : Less Training Error , high R^2 values\n",
    "\n",
    "3) CART Model gives least training error but we can see that cross validation scores are not good , this means that the model is \n",
    "overfitting\n",
    "\n",
    "4) Gradient Boosting Regressor performs the best in both Training Error and Cross Validation Scores Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Keeping the features as seen from EXPLORATORY DATA ANALYSIS\n",
    "'''\n",
    "\n",
    "midGTOData_train = midGTOData_train.reset_index()\n",
    "midGTOData_test = midGTOData_test.reset_index()\n",
    "target_train = midGTOData_train['Discount_Total']\n",
    "target_test = midGTOData_test['Discount_Total']\n",
    "colsToKeep = ['Volume_2019' , 'Volume_2018' ,'Volume_2019 Product' ,'Expected_GTO','Expected_product_volume' , 'profitability_indicator' , 'upper_limit'  ,'sdfc_Tier'  , 'loyalty_index' , 'Returnalility',  'inventory_lingering_factor', 'market_cap',\n",
    "       'order_size']\n",
    "features_train = midGTOData_train[colsToKeep]\n",
    "features_test = midGTOData_test[colsToKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ERROR =  2157.655855188812\n",
      "\n",
      "Linear Regression Model\n",
      "Cross Validation Scores:  [0.63800041 0.23246567 0.38247191 0.31567495 0.41035225 0.52893829\n",
      " 0.47113808 0.39799634 0.50792226 0.47252448]\n",
      "Mean Squared Error:  6583.829538001789\n",
      "MEAN CROSS VAL SCORES= 0.43574846519336735\n",
      "\n",
      "Random Forest Regressor\n",
      "TRAINING ERROR =  1424.0698486921524\n",
      "Cross Validation Scores:  [0.57852706 0.31551433 0.47641717 0.35457732 0.33568022 0.65900386\n",
      " 0.62967686 0.38368241 0.52126377 0.49137169]\n",
      "Mean Squared Error:  6414.869674902147\n",
      "MEAN CROSS VAL SCORES= 0.4745714696634106\n",
      "\n",
      "Lasso Regression Model\n",
      "TRAINING ERROR =  2157.662605321827\n",
      "Cross Validation Scores:  [0.63803764 0.23291445 0.38248092 0.31609428 0.41054297 0.52883927\n",
      " 0.47129861 0.398313   0.50578807 0.47294024]\n",
      "Mean Squared Error:  6583.274571440101\n",
      "MEAN CROSS VAL SCORES= 0.4357249459524747\n",
      "\n",
      "Ridge Regression Model\n",
      "TRAINING ERROR =  2158.0184294360824\n",
      "Cross Validation Scores:  [0.63808368 0.23631229 0.38197558 0.31789365 0.4114996  0.52757936\n",
      " 0.47113904 0.39978756 0.5003957  0.47526495]\n",
      "Mean Squared Error:  6581.304634455495\n",
      "MEAN CROSS VAL SCORES= 0.43599314105084713\n",
      "\n",
      "CART Regression Model\n",
      "TRAINING ERROR =  0.0\n",
      "Cross Validation Scores:  [ 0.45408064 -0.19818884 -0.12412526  0.16385192 -0.21969909  0.28979148\n",
      "  0.45214223 -0.06801739  0.20998934 -0.07351399]\n",
      "Mean Squared Error:  6427.821376094057\n",
      "MEAN CROSS VAL SCORES= 0.08863110390488926\n",
      "mse =  6359.643294209725\n",
      "\n",
      "Gradient Boosting Regressor\n",
      "TRAINING ERROR =  1411.5017787380566\n",
      "Cross Validation Scores:  [0.56251289 0.29534455 0.51148785 0.31107987 0.42174193 0.68639207\n",
      " 0.60258065 0.41217177 0.57332874 0.52340454]\n",
      "Mean Squared Error:  6359.643294209725\n",
      "MEAN CROSS VAL SCORES= 0.4900044850931503\n"
     ]
    }
   ],
   "source": [
    "methods = [x for x, y in Models.__dict__.items() if type(y) == FunctionType]\n",
    "methods.remove('__init__')\n",
    "for model in methods:\n",
    "    reg = Models(features_train, features_test, target_train, target_test)\n",
    "    cross_val_scores, mse = getattr(reg, model)(features_train, features_test, target_train, target_test)\n",
    "    print(\"MEAN CROSS VAL SCORES=\" , np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments for mid GTO Data\n",
    "1) CART REGRESSION MODEL OVERFITS , EVEN THOUGH WE HAVE zero Training error but cross validation scores are very less\n",
    "\n",
    "2) Gradient boosting Regressor has less training error and the highest k fold cross validation score\n",
    "\n",
    "3) GBR model fits best for mid GTO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Keeping the features as seen from EXPLORATORY DATA ANALYSIS\n",
    "'''\n",
    "\n",
    "\n",
    "highGTOData_train = highGTOData_train.reset_index()\n",
    "highGTOData_test = highGTOData_test.reset_index()\n",
    "target_train = highGTOData_train['Discount_Total']\n",
    "target_test = highGTOData_test['Discount_Total']\n",
    "colsToKeep = ['Volume_2019' , 'Volume_2018' ,'Volume_2019 Product' ,'Expected_GTO','Expected_product_volume' , 'profitability_indicator' , 'upper_limit'  ,  'inventory_lingering_factor',\n",
    "       'order_size']\n",
    "features_train = highGTOData_train[colsToKeep]\n",
    "features_test = highGTOData_test[colsToKeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ERROR =  11592.764707271046\n",
      "\n",
      "Linear Regression Model\n",
      "Cross Validation Scores:  [-1.06087019 -0.36632146  0.97420802  0.72035285  0.62682464 -0.06819141\n",
      "  0.49322678 -2.2610839   0.87362034  0.91377639]\n",
      "Mean Squared Error:  124995.12651733206\n",
      "MEAN CROSS VAL SCORES= 0.0845542055601822\n",
      "\n",
      "Random Forest Regressor\n",
      "TRAINING ERROR =  5966.083708326815\n",
      "Cross Validation Scores:  [-1.74860924  0.5434003   0.91425773  0.85503962  0.62815798 -0.09866692\n",
      "  0.46652807 -4.63388039  0.8523974   0.92125103]\n",
      "Mean Squared Error:  171986.4990619022\n",
      "MEAN CROSS VAL SCORES= -0.1300124437627878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8735745248.855309, tolerance: 17511858.16904576\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5648836278.466648, tolerance: 16989957.83912539\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6541686295.815524, tolerance: 17093948.063802466\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8427322473.458778, tolerance: 11503909.394607509\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7625020321.91488, tolerance: 16550956.939804306\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8032029901.700499, tolerance: 17078545.52190337\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8368239727.70475, tolerance: 17258069.28391088\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8239073469.532127, tolerance: 17242090.63033597\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8441414126.525116, tolerance: 17227179.79658202\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6920556723.114244, tolerance: 11651871.867754962\n",
      "  positive)\n",
      "C:\\Users\\NISARG\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7875674610.5744705, tolerance: 14860317.325613242\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Model\n",
      "TRAINING ERROR =  11592.8733428284\n",
      "Cross Validation Scores:  [-1.07080799 -0.36169851  0.97953099  0.72041248  0.62548444 -0.07059253\n",
      "  0.48980501 -2.07415161  0.87716266  0.91381811]\n",
      "Mean Squared Error:  124878.77966440414\n",
      "MEAN CROSS VAL SCORES= 0.1028963054053718\n",
      "\n",
      "Ridge Regression Model\n",
      "TRAINING ERROR =  11592.81823974513\n",
      "Cross Validation Scores:  [-1.05852978 -0.36697204  0.97403141  0.72024496  0.62874838 -0.06852993\n",
      "  0.49177446 -2.12594403  0.87364746  0.91384709]\n",
      "Mean Squared Error:  125016.88051406432\n",
      "MEAN CROSS VAL SCORES= 0.09823179709549928\n",
      "\n",
      "CART Regression Model\n",
      "TRAINING ERROR =  0.0\n",
      "Cross Validation Scores:  [ -1.5315511    0.56870987   0.95914696   0.77538861   0.46493835\n",
      "  -0.71221601   0.17658503 -28.61189892   0.86198964   0.93158534]\n",
      "Mean Squared Error:  169286.79460617268\n",
      "MEAN CROSS VAL SCORES= -2.611732223013262\n",
      "mse =  174374.6010934097\n",
      "\n",
      "Gradient Boosting Regressor\n",
      "TRAINING ERROR =  1573.8869325240246\n",
      "Cross Validation Scores:  [-1.86965283  0.5372397   0.9313883   0.50634274  0.57041546 -0.65942433\n",
      "  0.35410652 -1.99967836  0.82529292  0.94767677]\n",
      "Mean Squared Error:  174374.6010934097\n",
      "MEAN CROSS VAL SCORES= 0.014370688817669963\n"
     ]
    }
   ],
   "source": [
    "methods = [x for x, y in Models.__dict__.items() if type(y) == FunctionType]\n",
    "methods.remove('__init__')\n",
    "for model in methods:\n",
    "    reg = Models(features_train, features_test, target_train, target_test)\n",
    "    cross_val_scores, mse = getattr(reg, model)(features_train, features_test, target_train, target_test)\n",
    "    print(\"MEAN CROSS VAL SCORES=\" , np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments for High GTO Data\n",
    "1) Linear Models are seen to have better cross validation scores as compared to GBR even though they have higher training error\n",
    "\n",
    "2) Combining results of GBR & Lasso could be an ideal choice for High GTO Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Comments\n",
    "\n",
    "# Low GTO Data : GBR\n",
    "\n",
    "# Mid GTO Data : GBR\n",
    "\n",
    "# High GTO Data : GBR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
